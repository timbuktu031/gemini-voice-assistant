import webrtcvad
import pyaudio
import wave
import os
import sys
import contextlib

@contextlib.contextmanager
def suppress_alsa_errors():
    with open(os.devnull, 'w') as devnull:
        old_stderr = sys.stderr
        sys.stderr = devnull
        try:
            yield
        finally:
            sys.stderr = old_stderr

def record_audio(filename="input.wav"):
    vad = webrtcvad.Vad(2)
    with suppress_alsa_errors():
        audio = pyaudio.PyAudio()
        stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000,
                            input=True, frames_per_buffer=320)

        print("ğŸ¤ ì†Œë¦¬ ê°ì§€ ì¤‘... ë§í•˜ë©´ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤")

        frames = []
        triggered = False
        silence_count = 0

        try:
            while True:
                frame = stream.read(320, exception_on_overflow=False)
                is_speech = vad.is_speech(frame, 16000)

                if is_speech:
                    if not triggered:
                        print("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘!")
                        triggered = True
                    frames.append(frame)
                    silence_count = 0
                elif triggered:
                    frames.append(frame)
                    silence_count += 1
                    if silence_count > 20:
                        print("ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ")
                        break

        except Exception as e:
            print(f"âŒ ë…¹ìŒ ì˜¤ë¥˜: {e}")
        finally:
            stream.stop_stream()
            stream.close()
            audio.terminate()

        if frames:
            wf = wave.open(filename, 'wb')
            wf.setnchannels(1)
            wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
            wf.setframerate(16000)
            wf.writeframes(b''.join(frames))
            wf.close()
        else:
            print("âš ï¸ ë…¹ìŒëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
